* WORK SPACE

** elisp
#+begin_src emacs-lisp :results silent
  (save-buffer)
  (org-babel-tangle)
  ;; (async-shell-command "./tmp.sh" "log" "err")
#+end_src

** shell
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./tmp.sh
#+end_src


* First, set up the venv
I am using [[https://github.com/astral-sh/uv][uv]] as it is very fast.

** Create venv
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./venv_setup.sh
  uv venv "${HOME}/BEN2"
#+end_src

** Activate venv
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./venv_setup.sh
  . "${HOME}/BEN2/bin/activate"
#+end_src

** Install torch

*** For cpu
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./venv_setup.sh
  uv pip install \
      'torch' \
      'torchvision' \
      'torchaudio' \
      '--index-url' 'https://download.pytorch.org/whl/cpu' \
  ;
#+end_src

** Install other basic packages
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./venv_setup.sh
  uv pip install 'ipython' 'opencv-python' matplotlib tikzplotlib jpeg4py opencv-python lmdb pandas scipy loguru
#+end_src

** Function to download code from GITHUB
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./venv_setup.sh
  get_repo(){
      DIR_REPO="${HOME}/GITHUB/$('echo' "${1}" | 'sed' 's/^git@github.com://g ; s@^https://github.com/@@g ; s@.git$@@g' )"
      DIR_BASE="$('dirname' '--' "${DIR_REPO}")"

      mkdir -pv -- "${DIR_BASE}"
      cd "${DIR_BASE}"
      git clone "${1}"
      cd "${DIR_REPO}"

      if test "${#}" '-ge' '2'
      then
          git switch "${2}"
      else
          git switch main
      fi

      git pull
      git submodule update --recursive --init

      if test "${#}" '-ge' '3'
      then
          git checkout "${3}"
      fi
  }
#+end_src

** Download and install BEN2
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./venv_setup.sh
  get_repo 'https://github.com/PramaLLC/BEN2.git'
  uv pip install .
#+end_src

** Download and install SAMURAI
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./venv_setup.sh
  get_repo 'https://github.com/yangchris11/samurai.git'
  cd sam2
  uv pip install .
  uv pip install ".[notebooks]"
  cd checkpoints
  ./download_ckpts.sh
#+end_src

* Extract and set up the images

** Extract the zip
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./extract.sh
  unzip 'Weldnut.zip'
#+end_src

** Some cleanups
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./extract.sh
  rm -vrf -- '__MACOSX'
#+end_src

** Organize images and videos
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./convert.sh
  mkdir jpeg mov

  mv -vf 'Weldnut/IMG_0621 weldnut.jpeg' 'Weldnut/IMG_0628 weldnut.jpeg' 'Weldnut/IMG_0622 weldnut.jpeg' 'Weldnut/IMG_0623 weldnut.jpeg' 'Weldnut/IMG_0624 weldnut.jpeg' 'Weldnut/IMG_0625 weldnut.jpeg' 'Weldnut/IMG_0626 weldnut.jpeg' 'Weldnut/IMG_0627 weldnut.jpeg' 'jpeg'

  mv -vf 'Weldnut/IMG_0629 weldnut.MOV' 'Weldnut/IMG_0631-14 weldnut scan.MOV' 'Weldnut/IMG_0632-14 weldnut scan.MOV' 'Weldnut/IMG_0633-12 weldnut scan.MOV' 'Weldnut/IMG_0630-14 weldnut scan.MOV' 'mov'
#+end_src

** Convert jpeg to png to allow alpha info
This is done using [[http://www.graphicsmagick.org/][graphicsmagic]]
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./convert.sh
  mkdir -pv -- png
  convert './jpeg/IMG_0621 weldnut.jpeg' './png/IMG_0621 weldnut.png'
  convert './jpeg/IMG_0625 weldnut.jpeg' './png/IMG_0625 weldnut.png'
  convert './jpeg/IMG_0622 weldnut.jpeg' './png/IMG_0622 weldnut.png'
  convert './jpeg/IMG_0626 weldnut.jpeg' './png/IMG_0626 weldnut.png'
  convert './jpeg/IMG_0623 weldnut.jpeg' './png/IMG_0623 weldnut.png'
  convert './jpeg/IMG_0627 weldnut.jpeg' './png/IMG_0627 weldnut.png'
  convert './jpeg/IMG_0624 weldnut.jpeg' './png/IMG_0624 weldnut.png'
  convert './jpeg/IMG_0628 weldnut.jpeg' './png/IMG_0628 weldnut.png'
#+end_src

* Main code for segmenting the weldnut images

** Shell script to 
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./segment.sh
  . "${HOME}/BEN2/bin/activate"
  python3 ./segment.py
#+end_src

** Main python code

*** Import the libraries
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./segment.py
  from PIL import Image
  from ben2 import BEN_Base
  import cv2
  import numpy as np
  import os
  import torch
#+end_src

** Create directory to store the output files
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./segment.py
  os.makedirs(name='./mask/',  exist_ok=True)
#+end_src

** Device to run the model on
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./segment.py
  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
  model = BEN_Base.from_pretrained("PramaLLC/BEN2")
  model.to(device).eval()
#+end_src

** Main function to do the segmentation
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./segment.py
  def slave(name):
      image = Image.open("./png/" + name)
      foreground = model.inference(
          image,
          refine_foreground=False,
      )  # Refine foreground is an extract postprocessing step that increases inference time but can improve matting edges. The default value is False.

      foreground.save("./mask/" + name)
#+end_src

** Segment all the input images
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./segment.py
  for i in os.listdir("./png/"):
      slave(name=i)
#+end_src

** Extract the mask from RGBA images
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./segment.py
  def process_segment(img):
      return (img[:, :, 3] > 127).astype(np.uint8)
#+end_src

** Simple check to see the masks are good
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./segment.py
  def visualize(name):
      orig = cv2.imread("./png/" + name, cv2.IMREAD_COLOR)
      segm = cv2.imread("./mask/" + name, cv2.IMREAD_UNCHANGED)
      segm = process_segment(segm)
      masked = orig.copy()
      for i in range(3):
          masked[:, :, i] = orig[:, :, i] * segm
      final_array = np.array([orig, masked]).reshape((orig.shape[0]*2, orig.shape[1], 3))
      print(final_array.shape)

      os.makedirs(name="./vis/", exist_ok=True)
      cv2.imwrite("./vis/" + name, final_array)


  for i in os.listdir("./png/"):
      visualize(i)
#+end_src

** Misc code
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./segment.py
  def grow_mask(name):
      segm = cv2.imread("./mask/" + name, cv2.IMREAD_UNCHANGED)
      segm = process_segment(segm) * 255
      kernel1 = np.array(
          [
              [1, 1, 1, 1, 1],
              [1, 1, 1, 1, 1],
              [1, 1, 1, 1, 1],
              [1, 1, 1, 1, 1],
              [1, 1, 1, 1, 1],
          ]
      )
      segm = cv2.filter2D(src=segm, ddepth=-1, kernel=kernel1)
      cv2.imwrite("./mask/B_" + name, segm)


  for i in os.listdir("./png/"):
      grow_mask(i)
#+end_src

These produce almost perfect semantic segmentation masks, object detection at this stage is trivial.

* Code to extract bounding box
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./bbox.py
  from PIL import Image
  from ben2 import BEN_Base
  import cv2
  import numpy as np
  import os
  import torch


  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
  model = BEN_Base.from_pretrained("PramaLLC/BEN2")
  model.to(device).eval()


  def process_segment(img):
      return (img[:, :, 3] > 127).astype(np.uint8)


  def do_infer(image_PIL_input):
      foreground_PIL_output = model.inference(
          image_PIL_input,
          refine_foreground=False,
      )  # Refine foreground is an extract postprocessing step that increases inference time but can improve matting edges. The default value is False.
      return foreground_PIL_output


  def write_mask(path_file_image_input, path_file_mask_output):
      do_infer(image_PIL_input=Image.open(path_file_image_input)).save(
          path_file_mask_output
      )
      cv2.imwrite(
          path_file_mask_output,
          process_segment(img=cv2.imread(path_file_mask_output, cv2.IMREAD_UNCHANGED)),
      )


  def get_bbox(path_file_mask_input):
      mask_input = cv2.imread(path_file_mask_input, cv2.IMREAD_GRAYSCALE)
      rows = np.any(mask_input, axis=1)
      cols = np.any(mask_input, axis=0)
      r = np.where(rows)[0]
      c = np.where(cols)[0]

      if (r.flatten().shape[0] > 0) and (c.flatten().shape[0] > 0):
          rmin, rmax = r[[0, -1]]
          cmin, cmax = c[[0, -1]]
          return rmin.item(), cmin.item(), rmax.item(), cmax.item()
      else:
          return 0, 0, mask_input.shape[0] - 1, mask_input.shape[1] - 1


  def image_2_bbox(path_prefix_input):
      write_mask(
          path_file_image_input=path_prefix_input + ".png",
          path_file_mask_output=path_prefix_input + "_M.png",
      )
      y1, x1, y2, x2 = get_bbox(path_file_mask_input=path_prefix_input + "_M.png")
      with open(path_prefix_input + "_bbox.txt", "w", encoding="utf-8") as f:
          f.write(str(x1) + "," + str(y1) + "," + str(x2) + "," + str(y2))


  image_2_bbox(path_prefix_input="./mp4/IMG_0629 weldnut.dir/1")
#+end_src

* Track in video

** Convert videos to more standard format

*** Function to convert
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./convert.sh
  W(){
      ffmpeg -i "mov/${1}.MOV" "mp4/${1}.mp4" -c:v libx264
  }
#+end_src

*** Convert all videos
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./convert.sh
  W 'IMG_0629 weldnut'
  W 'IMG_0630-14 weldnut scan'
  W 'IMG_0631-14 weldnut scan'
  W 'IMG_0632-14 weldnut scan'
  W 'IMG_0633-12 weldnut scan'
#+end_src

** Extract first frame

*** Function to extract
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./convert.sh
  W(){
      mkdir -pv -- "mp4/${1}.dir"
      ffmpeg -i "mp4/${1}.mp4" -r 1 "mp4/${1}.dir/%d.png" 
  }
#+end_src

*** get from all videos
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./convert.sh
  W 'IMG_0629 weldnut'
  W 'IMG_0630-14 weldnut scan'
  W 'IMG_0631-14 weldnut scan'
  W 'IMG_0632-14 weldnut scan'
  W 'IMG_0633-12 weldnut scan'
#+end_src

#+begin_src sh :shebang #!/bin/sh :results output :tangle ./track.sh
  . "${HOME}/BEN2/bin/activate"
  VIDEO_FILE="$(realpath "${1}")"
  TEXT_BBOX_FILE="$(realpath "${2}")"
  cd "${HOME}/GITHUB/yangchris11/samurai"
  python3 "${HOME}/GITHUB/yangchris11/samurai/scripts/demo.py" \
      --video_path "${VIDEO_FILE}" \
      --txt_path "${TEXT_BBOX_FILE}" \
  ;
#+end_src

./track.sh 'mp4/IMG_0629 weldnut.mp4' 'mp4/IMG_0629 weldnut.dir/1_bbox.txt'
